library(rjson)
b <- fromJSON("http://api.vkontakte.ru/method/getProfiles?uid=1&fields=sex")
b <- fromJSON("http://api.vkontakte.ru/method/getProfiles?uid=1&fields=sex", [1])
b <- fromJSON(readLines("http://api.vkontakte.ru/method/getProfiles?uid=1&fields=sex")[1])
b <- fromJSON(readLines("http://api.vkontakte.ru/method/getProfiles?uid=1&fields=sex")[0])
b
b <- fromJSON(readLines("http://api.vkontakte.ru/method/getProfiles?uid=1&fields=sex")[1])
b
b[11]
b[1]
class(b)
b[0]
b[1]
names(b)
data.frame(b)
pp <- data.frame(b)
pp
for (j in 1:50) {
b <- fromJSON(readLines(paste0("http://api.vkontakte.ru/method/getProfiles?uid=", j, "1&fields=sex"))[1])
}
warnings()
b
bl <- list()
for (j in 1:50) {
bl <- c(bl, fromJSON(readLines(paste0("http://api.vkontakte.ru/method/getProfiles?uid=", j, "&fields=sex"))[1]))
}
bl
data.frame(bl)
bb <- data.frame(bl)
head(bb)
names(bb)
bl[1]
class(bl)
class(bl[1])
class(bl[[1])
class(bl[[1]])
bl[[1]]
names(bl[[1]])
x<- fromJSON('{"ok":true}')
x
x[1]
x[[1]]
names(x)
x$ok
bl
names(bl)
bl$response
bl[[3]]
class(bl[[3]])
names(bl[[3]])
names(bl[[3]][1])
names(bl[[3]][[1]])
names(bl[[8]][[1]])
names(bl[[11]][[1]])
bl[[11]][[1]]
bl[[11]][[1]]$uid
bl[[11]][[1]]$first_name
class(bl[[11]][[1]]$first_name)
a <- list(n1="10", n2="11")
a
b <- list(n1="20", n2="21")
data.frame(a,b)
data.frame(a)
cc <-data.frame(a)
data.frame(cc,b)
do.call("rbind", bl)
bl[[11]][[1]]
for (j in 1:50) {
bl <- c(bl, fromJSON(readLines(paste0("http://api.vkontakte.ru/method/getProfiles?uid=", j, "&fields=sex"))[1])[[1]][[1]])
}
bl
unlist(bl)
rbind(bl)
r <- rnorm(100)
r
plot(r)
hist(r)
hist(r, 10)
hist(r, 20)
hist(r, 100)
r <- rnorm(10000)
str(r)
hist(r, 100)
r <- rnorm(10000000)
hist(r, 100)
hist(r, 10)
hist(r, 200)
r <-dnorm(100)
r
r <- dnorm(100, 1, 1)
r
r <- rnorm(100, 1, 1)
r
hist(r, 200)
r <- rnorm(10000, 1, 1)
hist(r, 200)
r <- rnorm(10000, 1,6)
hist(r, 200)
plot(r)
b <-r*2
b
plto(r,b)
plot(r,b)
b <- r * rnorm(10000, 1, 1)
b
plot(r,b)
r <- rnorm(10000, 10, 1)
plot(r,b)
hist(r)
hist(r, 100)
set.seed(20)
x <- rnorm(100)
y <- rnorm(100, 0, 2)
e <- rnorm(100, 0, 2)
y <- 0.5 + 2*x + e
plot(x,y)
summary(y)
hist(x)
hist(e)
hist(y)
set.seed(10)
x <- rbinom(100, 1, 0.5)
hist(x)
x
e <- rnorm(100,0,2)
y <- 0.5 +2*x +e
summary(y)
plot(x,y)
set.seed(1)
x <- rnorm(100)
log.mu <- 0.5 + 0.3*x
log.mu
y <- rpois(100, exp(log.mu))
y
str(y)
plot(x,y)
sample(letters)
sample(letters,1)
sample(letters,22)
sample(letters,400)
sample(letters,400, replace = T)
b<-sample(letters,400, replace = T)
b
hist(b)
plot(b)
c<-split(b)
c<-split(b, b)
c
str(b)
str(c)
tapply(c)
tapply(c, b)
tapply(c, c)
tapply(c, 1:16)
tapply(c, 1:26)
b
sample(b,3)
set.seed(1)
rpois(5,2)
pnorm(70, mean = 80, sd = 10)
qborn(0.95, mean=1100, sd = 75)
qnorm(0.95, mean=1100, sd = 75)
qnorm(0.95, mean=1100, sd = 75/sqrt(100))
pbinom(3 , prob = 0.5, size =5, lower.tail= FALSE)
pbinom(1 , prob = 0.5, size =5, lower.tail= FALSE)
pbinom(2 , prob = 0.5, size =5, lower.tail= FALSE)
pbinom(10 , prob = 0.5, size =5, lower.tail= FALSE)
pbinom(10 , prob = 0.5, size =5)
pbinom(2 , prob = 0.5, size =5)
pbinom(5 , prob = 0.5, size =5)
choose(8,7)
choose(8,7)
choose(8,8)
choose?
()
?choose
1100 + c(-1,1) * qt(0.975, df = 9) * 30 / sqrt(9)
(0 + 2 * sqrt(9))/qt(0.975, df = 8)
library(AppliedPredictiveModeling)
install.packages("AppliedPredictiveModeling")
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
install.packages("caret")
library(caret)
install.packages("pbkrtest")
updateR()
install.packages("installr")
library(AppliedPredictiveModeling)
data(concrete)
library(caret)
install.packages("pbkrtest")
set.seed(1000)
library(caret)
set.seed(1000)
inTrain = createDataPartition(mixtures$CompressiveStrength, p = 3/4)[[1]]
training = mixtures[ inTrain,]
testing = mixtures[-inTrain,]
library(caret)
library(AppliedPredictiveModeling)
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]training = adData[ inTrain,]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
idx <- grep("^[Ii][Ll].*", names(training))
preObj <- preProcess(training[,idx], method = c("center", "scale", "pca"), thresh = 0.8)
preObj
names(preObj)
library(XML)
html.raw<-htmlTreeParse("https://www.reformagkh.ru/myhouse?sort=name&order=asc&page=1&limit=100")
summary(html.raw)
html.raw
html.raw[1]
html.raw[2]
html.raw[3]
r_url<-htmlTreeParse("https://www.reformagkh.ru/myhouse?sort=name&order=asc&page=1&limit=100"
readHTMLTable(r_url)
a<-readHTMLTable(r_url)
r_url<-"https://www.reformagkh.ru/myhouse?sort=name&order=asc&page=1&limit=100"
a<-readHTMLTable(r_url)
a
a[1]
a[2]
a[0]
a[[0]]
a[0][0]
a[0][1]
n.rows <- unlist(lapply(a, function(t) dim(t)[1]))
tables[[which.max(n.rows)]]
a[[which.max(n.rows)]]
a<-readHTMLTable(r_url)
data_df <- readHTMLTable(r_url)
doc.html = htmlTreeParse(r_url, useInternal = TRUE)
class(doc.html)
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
doc.text
head(doc.html)
head(doc.text)
summary(doc.text)
doc.html = htmlTreeParse(r_url, useInternal = TRUE)
r_url<-'https://www.reformagkh.ru/myhouse?sort=name&order=asc&page=1&limit=100'
doc.html = htmlTreeParse(r_url, useInternal = TRUE)
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
doc.text
library(curl)
library(RCurl)
doc<-getURL(r_url)
doc
doc.html = htmlTreeParse(doc, useInternal = TRUE)
doc.text = unlist(xpathApply(doc.html, '//p', xmlValue))
doc.text
doc.text = unlist(xpathApply(doc.html, '//td', xmlValue))
doc.text
r_url<-'https://www.reformagkh.ru/myhouse?sort=name&order=asc&page=1&limit=100'
doc<-getURL(r_url)
doc
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
train_ds <- createDataPartition(y = segmentationOriginal$Case, p = 0.6, list = FALSE)
head(segmentationOriginal)
training <- segmentationOriginal[train_ds,]
testing <- segmentationOriginal[-train_ds,]
set.seed(125)
modFit <- train(Class ~ ., method = "rpart", data = training)
install.packages("e1071")
modFit <- train(Class ~ ., method = "rpart", data = training)
modFit$finalModel
suppressMessages(library(rattle))
install.packages("rattle")
suppressMessages(library(rattle))
library(rpart.plot)
install.packages("rpart.plot")
library(rpart.plot)
fancyRpartPlot(modFit$finalModel)
library(pgmm)
install.packages("pgmm")
library(pgmm)
data(olive)
olive = olive[,-1]
newdata = as.data.frame(t(colMeans(olive)))
modolive <- train(Area ~ ., method = "rpart", data = olive)
predict(modolive, newdata = newdata)
library(ElemStatLearn)
install.packages("ElemStatLearn")
library(ElemStatLearn)
data(SAheart)
set.seed(8484)
train = sample(1:dim(SAheart)[1],size=dim(SAheart)[1]/2,replace=F)
trainSA = SAheart[train,]
testSA = SAheart[-train,]
set.seed(13234)
missClass = function(values, prediction) {sum(((prediction > 0.5) * 1) != values) / length(values)}
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl,
data = trainSA, method = "glm", family = "binomial")
modelSA <- train(chd ~ age + alcohol + obesity + tobacco + typea + ldl, data = trainSA, method = "glm", family = "binomial")
missClass(testSA$chd, predict(modelSA, newdata = testSA))
missClass(trainSA$chd, predict(modelSA, newdata = trainSA))
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
set.seed(33833)
library(randomForest)
install.packages("randomForest")
library(randomForest)
modvowel <- randomForest(y ~ ., data = vowel.train)
order(varImp(modvowel), decreasing = T)
library(ElemStatLearn)
data(vowel.train)
data(vowel.test)
set.seed(33833)
head(vowel.train)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
head(vowel.train)
model_rf <- train(y ~ ., data = vowel.train, method = "rf")
library(caret)
model_rf <- train(y ~ ., data = vowel.train, method = "rf")
model_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(model_rf, vowel.test)
pred_gbm <- predict(model_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
pred_DF <- data.frame(pred_rf, pred_gbm, y = vowel.test$y)
head(pred_DF)
pred_DF
sum(pred_rf[pred_DF$pred_rf == pred_DF$pred_gbm] == pred_DF$y[pred_DF$pred_rf == pred_DF$pred_gbm]) /
sum(pred_DF$pred_rf == pred_DF$pred_gbm)
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
confusionMatrix(pred_gbm, vowel.test$y)$overall[1]
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerPredictiveModeling)
data(AlzheimerDesise)
data(AlzheimerDesease)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
head(adData)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
pred_DF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = pred_DF)
compPred <- predict(combModFit, pred_DF)
confusionMatrix(pred_rf, testing$diagnosis)$overall[[1]]
confusionMatrix(pred_rf, testing$diagnosis)$overall[[1]]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[[1]]
confusionMatrix(pred_lda, testing$diagnosis)$overall[[1]]
confusionMatrix(compPred, testing$diagnosis)$overall[[1]]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(233)
head(concrete)
mod_lasso <- train(CompressiveStrength ~ ., ddata = training, method = "lasso")
mod_lasso <- train(CompressiveStrength ~ ., data = training, method = "lasso")
library(elasticnet)
plot.enet(mod_lasso$finalModel, xvar = "penalty", use.color = TRUE)
library(lubridate) # For year() function below
dat = read.csv("gaData.csv")
setwd("~/Coursera/PracticalMachineLearning/Quiz4")
dat = read.csv("gaData.csv")
setwd("~/Coursera/PracticalMachineLearning/Quiz4")
training = dat[year(dat$date) < 2012,]
testing = dat[(year(dat$date)) > 2011,]
tstrain = ts(training$visitsTumblr)
library(forecast)
install.packages("forecast")
library(forecast)
mod_ts <- bats(tstrain)
fcast <- forecast(mod_ts, level = 95, h = dim(testing)[1])
sum(fcast$lower < testing$visitsTumblr & testing$visitsTumblr < fcast$upper) / dim(testing)[1]
set.seed(3523)
library(AppliedPredictiveModeling)
data(concrete)
inTrain = createDataPartition(concrete$CompressiveStrength, p = 3/4)[[1]]
training = concrete[ inTrain,]
testing = concrete[-inTrain,]
set.seed(325)
library(e1071)
mod_svm <- svm(CompressiveStrength ~ ., data = training)
pred_svm <- predict(mod_svm, testing)
accuracy(pred_svm, testing$CompressiveStrength)
library(caret)
library(gbm)
set.seed(3433)
library(AppliedPredictiveModeling)
data(AlzheimerDisease)
adData = data.frame(diagnosis, predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[inTrain, ]
testing = adData[-inTrain, ]
set.seed(62433)
mod_rf <- train(diagnosis ~ ., data = training, method = "rf")
mod_gbm <- train(diagnosis ~ ., data = training, method = "gbm")
mod_lda <- train(diagnosis ~ ., data = training, method = "lda")
pred_rf <- predict(mod_rf, testing)
pred_gbm <- predict(mod_gbm, testing)
pred_lda <- predict(mod_lda, testing)
pred_DF <- data.frame(pred_rf, pred_gbm, pred_lda, diagnosis = testing$diagnosis)
combModFit <- train(diagnosis ~ ., method = "rf", data = pred_DF)
compPred <- predict(combModFit, pred_DF)
confusionMatrix(pred_rf, testing$diagnosis)$overall[[1]]
confusionMatrix(pred_gbm, testing$diagnosis)$overall[[1]]
confusionMatrix(pred_lda, testing$diagnosis)$overall[[1]]
confusionMatrix(compPred, testing$diagnosis)$overall[[1]]
confusionMatrix(pred_rf, vowel.test$y)
library(ElemStatLearn)
library(caret)
data(vowel.train)
data(vowel.test)
set.seed(33833)
vowel.train$y <- as.factor(vowel.train$y)
vowel.test$y <- as.factor(vowel.test$y)
model_rf <- train(y ~ ., data = vowel.train, method = "rf")
model_gbm <- train(y ~ ., data = vowel.train, method = "gbm")
pred_rf <- predict(model_rf, vowel.test)
pred_gbm <- predict(model_gbm, vowel.test)
confusionMatrix(pred_rf, vowel.test$y)
confusionMatrix(pred_rf, vowel.test$y)$overall
confusionMatrix(pred_rf, vowel.test$y)$overall[1]
library(caret)
set.seed(9988)
setwd("~/Coursera/PracticalMachineLearning/CourseProject")
train_path <- "pml-training.csv"
test_path <- "pml-testing.csv"
training <- read.csv(train_path, na.strings = c("NA", ""))
testing <- read.csv(test_path, na.strings = c("NA", ""))
head(training)
inTrain <- createDataPartition(y = training$classe, p = 0.6, list = FALSE)
training_data <- training[inTrain, ]
testing_data <- training[-inTrain, ]
dim(training_data)
dim(testing_data)
nzv <- nearZeroVar(training_data, saveMetrics = TRUE)
head(nzv)
nzv
training_data <- training_data[, -nzv]
inTrain <- createDataPartition(y = training$classe, p = 0.6, list = FALSE)
training_data <- training[inTrain, ]
testing_data <- training[-inTrain, ]
dim(training_data)
dim(testing_data)
nzv <- nearZeroVar(training_data, saveMetrics = TRUE)
training_data <- training_data[, -nzv]
testing_data <- testing_data[, -nzv]
nzv <- nearZeroVar(training_data)
training_data <- training_data[, -nzv]
testing_data <- testing_data[, -nzv]
NA_mark <- sapply(training_data, function(x) mean(is.na(x))) > 0.95
NA_mark
summary(NA_mark)
training_data <- training_data[, NA_mark == FALSE]
testing_data <- testing_data[, NA_mark == FALSE]
summary(testing_data)
fit <- train(classe ~ ., data = training_data, method = "rf", trControl = fitControl)
fitControl <- trainControl(method = "cv", number = 4, verboseIter = FALSE)
fit <- train(classe ~ ., data = training_data, method = "rf", trControl = fitControl)
fit$finalModel
predictions <- predict(fit, testing_data)
confusionMatrix(testing_data$classe, predictions)
nzv <- nearZeroVar(training)
full_train <- training[, -nzv]
full_test <- testing[, -nzv]
NA_mark <- sapply(full_train, function(x) mean(is.na(x))) > 0.95
full_train <- full_train[, NA_mark == FALSE]
full_test <- full_test[, NA_mark == FALSE]
fitControl <- trainControl(method = "cv", number = 4, verboseIter = FALSE)
fit <- train(classe ~ ., data = full_train, method = "rf", trControl = fitControl)
predictions <- predict(fit, full_test)
confusionMatrix(predictions, full_test$classe)
fitControl <- trainControl(method = "cv", number = 4, verboseIter = FALSE)
confusionMatrix(full_test$classe, predictions)
full_test <- full_test[, NA_mark == FALSE]
NA_mark <- sapply(full_train, function(x) mean(is.na(x))) > 0.95
full_test <- full_test[, NA_mark == FALSE]
predictions <- predict(fit, full_test)
confusionMatrix(full_test$classe, predictions)
summary(full_test)
print(predictions)
fit$finalModel
dim(predictions)
dim(full_test)
predictions
predictions <- predict(fit, full_test)
confusionMatrix(full_test$classe, predictions)
predictions
as.character(predictions)
confusionMatrix(full_test$classe, predictions)
fit$finalModel
predictions <- predict(fit, full_test)
confusionMatrix(full_test$classe, predictions)
predictions
